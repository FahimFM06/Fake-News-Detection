# -*- coding: utf-8 -*-
"""2_Input.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YpxCjuqfOruroXTZAWL4YdZ_oXzC9krW
"""

# pages/2_Input.py
# ============================================================
# Page 2: Input Page (paste text + run prediction)
# ============================================================

import base64
import os
import numpy as np
import streamlit as st
import torch

from transformers import AutoTokenizer, AutoModelForSequenceClassification

st.set_page_config(page_title="Input - Fake News Detection", layout="wide")

def set_background(image_path: str):
    """
    Sets a background image if it exists; otherwise uses a clean gradient.
    """
    if os.path.exists(image_path):
        import base64
        with open(image_path, "rb") as f:
            data = f.read()
        b64 = base64.b64encode(data).decode()
        st.markdown(
            f"""
            <style>
            .stApp {{
                background: url("data:image/png;base64,{b64}") no-repeat center center fixed;
                background-size: cover;
            }}
            .content-card {{
                background: rgba(255, 255, 255, 0.90);
                padding: 24px;
                border-radius: 16px;
                max-width: 1100px;
                margin: 0 auto;
                box-shadow: 0 8px 26px rgba(0,0,0,0.12);
            }}
            </style>
            """,
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            """
            <style>
            .stApp {
                background: linear-gradient(135deg, #0b1220 0%, #111827 55%, #0f172a 100%);
            }
            .content-card {
                background: rgba(255, 255, 255, 0.92);
                padding: 24px;
                border-radius: 16px;
                max-width: 1100px;
                margin: 0 auto;
                box-shadow: 0 8px 26px rgba(0,0,0,0.18);
            }
            </style>
            """,
            unsafe_allow_html=True,
        )

# Optional: place an image at assets/bg_input.png
set_background("assets/bg_input.png")

# -----------------------------
# Model configuration
# -----------------------------
# Put your saved model folder here (relative to project folder).
# Example: model/roberta_fake_news_model
MODEL_DIR = "model/roberta_fake_news_model"
MAX_LEN = 256

# -----------------------------
# Cache the model/tokenizer so it loads once
# -----------------------------
@st.cache_resource
def load_model_and_tokenizer(model_dir: str):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)
    model = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)
    model.eval()
    return device, tokenizer, model

def predict(text: str):
    """
    Returns:
      label (int): 0=FAKE, 1=REAL
      probs (list): [p_fake, p_real]
    """
    device, tokenizer, model = load_model_and_tokenizer(MODEL_DIR)

    text = "" if text is None else str(text).strip()
    enc = tokenizer(
        [text],
        padding=True,
        truncation=True,
        max_length=MAX_LEN,
        return_tensors="pt"
    )
    enc = {k: v.to(device) for k, v in enc.items()}

    with torch.no_grad():
        logits = model(**enc).logits
        probs = torch.softmax(logits, dim=1).detach().cpu().numpy()[0]

    label = int(np.argmax(probs))
    return label, probs.tolist()

# Session defaults
if "input_text" not in st.session_state:
    st.session_state["input_text"] = ""
if "prediction" not in st.session_state:
    st.session_state["prediction"] = None

st.markdown('<div class="content-card">', unsafe_allow_html=True)
st.title("Input News Text")

st.write("Paste a headline or full article text. The model will predict **FAKE (0)** or **REAL (1)**.")

# Example text button (optional)
col_a, col_b = st.columns([1, 1])
with col_a:
    if st.button("Use Example Text"):
        st.session_state["input_text"] = (
            "WASHINGTON (Reuters) - The government announced new measures today as officials responded to concerns..."
        )
with col_b:
    if st.button("Clear"):
        st.session_state["input_text"] = ""
        st.session_state["prediction"] = None

text = st.text_area(
    "News Text",
    value=st.session_state["input_text"],
    height=220,
    placeholder="Paste your news text here..."
)

# Update session state with the latest input
st.session_state["input_text"] = text

# Simple input validation
char_count = len(text.strip())
st.caption(f"Character count: {char_count}")

predict_clicked = st.button("Predict")

if predict_clicked:
    if char_count < 20:
        st.warning("Please enter at least 20 characters for a meaningful prediction.")
    else:
        with st.spinner("Running RoBERTa inference..."):
            label, probs = predict(text)

        st.session_state["prediction"] = {
            "label": label,
            "probs": probs  # [p_fake, p_real]
        }

        st.success("Prediction completed. Open the **Result** page from the sidebar to view details.")

st.markdown("</div>", unsafe_allow_html=True)